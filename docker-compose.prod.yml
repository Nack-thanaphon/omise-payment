services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: payment-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: payment_service
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for Queue Management
  redis:
    image: redis:7-alpine
    container_name: payment-redis
    restart: unless-stopped
    volumes:
      - redis_data:/data
    ports:
      - "6380:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # New Backend Service (Hello World)
  backend-service:
    build: ./application/backend-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3000
    healthcheck:
      test: ["CMD-SHELL", "curl -sL http://localhost:3000 || exit 1"]
      interval: 10s # Check every 10 seconds
      timeout: 5s # Allow 5 seconds for a response
      retries: 5 # Retry 5 times before marking as unhealthy
      start_period: 20s # Give the container 20 seconds to start before health checks begin
    deploy:
      replicas: 2 # Run 2 instances of the new backend service
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: "0.3"
          memory: "256M"

  # Payment Service API
  payment-service:
    build: ./application/payment-service
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      NODE_ENV: production
      PORT: 3000
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USERNAME: postgres
      DB_PASSWORD: password
      DB_NAME: payment_service
      REDIS_HOST: redis
      REDIS_PORT: 6379
      OMISE_PUBLIC_KEY: ${OMISE_PUBLIC_KEY:-pkey_test_xxxxxxxxxxxxxxxxxxxxx}
      OMISE_SECRET_KEY: ${OMISE_SECRET_KEY:-skey_test_xxxxxxxxxxxxxxxxxxxxx}
      OMISE_WEBHOOK_SECRET: ${OMISE_WEBHOOK_SECRET:-whsec_test_xxxxxxxxxxxxxxxxxxxxx}
    volumes:
      - ./logs:/app/logs
    # Remove direct port mapping since Nginx will handle exposure
    # ports:
    #   - "3000:3000"
    healthcheck:
      test:
        ["CMD-SHELL", "curl -f http://localhost:3000/api/v1/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s # Give the payment service more time to start due to DB/Redis dependencies
    deploy: # Configure deployment for scaling
      replicas: 3 # Run 3 instances of the payment service
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: "0.5" # Limit CPU to 50% of one core
          memory: "512M" # Limit memory to 512MB

  # Payment Worker (Queue Processor)
  payment-worker:
    build: ./application/payment-service
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      frontend:
        condition: service_healthy # Ensure frontend is healthy before worker starts
      backend-service:
        condition: service_healthy # New backend service dependency
    environment:
      NODE_ENV: production
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USERNAME: postgres
      DB_PASSWORD: password
      DB_NAME: payment_service
      REDIS_HOST: redis
      REDIS_PORT: 6379
    command: ["npm", "run", "start:prod"]
    volumes:
      - ./logs:/app/logs

  # Frontend Application
  frontend:
    build: ./application/front-end # Assuming your frontend is here
    restart: unless-stopped
    depends_on:
      - backend-service # Frontend depends on the new backend service
    environment:
      NODE_ENV: production
      PORT: 3001 # Frontend usually runs on a different port, e.g., 3001 for Next.js
      NEXT_PUBLIC_API_BASE_URL: http://nginx:80/api # Nginx will proxy to backend
    # No direct port mapping since Nginx will handle exposure
    # ports:
    #   - "3001:3001"
    healthcheck:
      test: ["CMD-SHELL", "curl -sL http://localhost:3001 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s # Give the frontend application more time to start and build
    deploy: # Configure deployment for scaling
      replicas: 2 # Run 2 instances of the frontend service
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: "0.3" # Limit CPU
          memory: "256M" # Limit memory

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    depends_on:
      - payment-service
      - frontend # Add frontend as a dependency
      - backend-service # Add new backend service as a dependency
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --quiet --tries=1 --spider http://localhost || exit 1",
        ]
      interval: 10s # Check more frequently
      timeout: 5s
      retries: 5
      start_period: 10s # Give Nginx a short period to start

volumes:
  postgres_data:
  redis_data:
